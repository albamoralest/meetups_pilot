{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45b7e354-d0ca-4d55-a768-b858e02be3d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input\n",
    "outputIndex = 0\n",
    "outputFile = 'meetupType/prototypeSentences_' + outputIndex + '.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7833f920-4f6b-4695-a648-edd9c7afbdfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Music making': ['Conduct', 'Perform', 'Join', 'Produce', 'Write', 'Sing', 'Play', 'Song', 'Record'], 'Business meeting': ['Sign', 'Agree', 'Contract', 'Commit', 'Retire', 'Career', 'Hire', 'Debut'], 'Personal life': ['Born', 'Die', 'Marry', 'Divorce', 'Adult', 'Child', 'Elder', 'Young', 'Father', 'Mother', 'Family'], 'Coincidence': ['Meet', 'Stumble', 'Encounter', 'Find', 'Discover', 'Trigger'], 'Public celebration': ['Award', 'Ceremony', 'Marriage', 'Funeral', 'Public', 'Celebration'], 'Education': ['Learn', 'Teach', 'Mentor', 'Degree', 'University', 'Academia', 'Conservatoire']}\n"
     ]
    }
   ],
   "source": [
    "# Prepare seed terms for each meetup type\n",
    "\n",
    "meetup_types = {\"Music making\" : [\n",
    "\"Conduct\",\n",
    "\"Perform\",\n",
    "\"Join\",\n",
    "\"Produce\",\n",
    "\"Write\",\n",
    "\"Sing\",\n",
    "\"Play\",\n",
    "# \"Song\",\n",
    "\"Record\"],\n",
    "\"Business meeting\": [\n",
    "\"Sign\",\n",
    "\"Agree\",\n",
    "\"Contract\",\n",
    "\"Commit\",\n",
    "\"Retire\",\n",
    "\"Career\",\n",
    "\"Hire\",\n",
    "\"Debut\"],\n",
    "\"Personal life\": [\n",
    "\"Born\",\n",
    "\"Die\",\n",
    "\"Marry\",\n",
    "\"Divorce\",\n",
    "\"Adult\",\n",
    "\"Child\",\n",
    "\"Elder\",\n",
    "\"Young\",\n",
    "\"Father\",\n",
    "\"Mother\",\n",
    "\"Family\"],\n",
    "\"Coincidence\": [\n",
    "\"Meet\",\n",
    "\"Stumble\",\n",
    "\"Encounter\",\n",
    "\"Find\",\n",
    "\"Discover\",\n",
    "\"Trigger\"],\n",
    "\"Public celebration\": [\n",
    "\"Award\",\n",
    "\"Ceremony\",\n",
    "\"Marriage\",\n",
    "\"Funeral\",\n",
    "\"Public\",\n",
    "\"Celebration\"],\n",
    "\"Education\": [\n",
    "\"Learn\",\n",
    "\"Teach\",\n",
    "\"Mentor\",\n",
    "\"Degree\",\n",
    "\"University\",\n",
    "\"Academia\",\n",
    "\"Conservatoire\"]}\n",
    "\n",
    "print(meetup_types)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a3d87bb5-e7ab-4122-8cb4-556551ae2359",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gather prototype sentences and assign them to types\n",
    "#### Sentence -> lemmas -> match any seed\n",
    "# Compare query sentences with seed via sentence embeddings\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3ea29055-8141-4c9a-88a8-17653a00d8f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1002  files\n",
      "100  samples\n",
      "['indexedSentences/155965.csv', 'indexedSentences/2553132.csv', 'indexedSentences/1103482.csv', 'indexedSentences/1882145.csv', 'indexedSentences/493715.csv', 'indexedSentences/3614145.csv', 'indexedSentences/1186480.csv', 'indexedSentences/312781.csv', 'indexedSentences/45968.csv', 'indexedSentences/1310858.csv', 'indexedSentences/1422240.csv', 'indexedSentences/3606301.csv', 'indexedSentences/238175.csv', 'indexedSentences/1253783.csv', 'indexedSentences/3488554.csv', 'indexedSentences/3372135.csv', 'indexedSentences/2672499.csv', 'indexedSentences/3190132.csv', 'indexedSentences/1253793.csv', 'indexedSentences/966302.csv', 'indexedSentences/577944.csv', 'indexedSentences/2512661.csv', 'indexedSentences/523339.csv', 'indexedSentences/45450.csv', 'indexedSentences/1277042.csv', 'indexedSentences/589693.csv', 'indexedSentences/2508330.csv', 'indexedSentences/2508150.csv', 'indexedSentences/3227606.csv', 'indexedSentences/322567.csv', 'indexedSentences/3535198.csv', 'indexedSentences/696825.csv', 'indexedSentences/450629.csv', 'indexedSentences/1413790.csv', 'indexedSentences/309084.csv', 'indexedSentences/1239372.csv', 'indexedSentences/886285.csv', 'indexedSentences/140632.csv', 'indexedSentences/370445.csv', 'indexedSentences/2475284.csv', 'indexedSentences/105767.csv', 'indexedSentences/1322881.csv', 'indexedSentences/3689332.csv', 'indexedSentences/154038.csv', 'indexedSentences/144196.csv', 'indexedSentences/878467.csv', 'indexedSentences/948305.csv', 'indexedSentences/368130.csv', 'indexedSentences/2553865.csv', 'indexedSentences/50902387.csv', 'indexedSentences/1551347.csv', 'indexedSentences/1000228.csv', 'indexedSentences/3141790.csv', 'indexedSentences/177293.csv', 'indexedSentences/17902.csv', 'indexedSentences/1883095.csv', 'indexedSentences/98217.csv', 'indexedSentences/50931287.csv', 'indexedSentences/479958.csv', 'indexedSentences/866345.csv', 'indexedSentences/340945.csv', 'indexedSentences/1410438.csv', 'indexedSentences/756836.csv', 'indexedSentences/1234606.csv', 'indexedSentences/379324.csv', 'indexedSentences/1291198.csv', 'indexedSentences/129194.csv', 'indexedSentences/3365880.csv', 'indexedSentences/51449857.csv', 'indexedSentences/20215.csv', 'indexedSentences/2890708.csv', 'indexedSentences/1092607.csv', 'indexedSentences/415848.csv', 'indexedSentences/20484.csv', 'indexedSentences/827409.csv', 'indexedSentences/2296293.csv', 'indexedSentences/2524294.csv', 'indexedSentences/630312.csv', 'indexedSentences/3358257.csv', 'indexedSentences/1127222.csv', 'indexedSentences/52837049.csv', 'indexedSentences/1420817.csv', 'indexedSentences/362368.csv', 'indexedSentences/3391490.csv', 'indexedSentences/833109.csv', 'indexedSentences/2423427.csv', 'indexedSentences/2727386.csv', 'indexedSentences/2755844.csv', 'indexedSentences/280945.csv', 'indexedSentences/51129468.csv', 'indexedSentences/1351998.csv', 'indexedSentences/50655124.csv', 'indexedSentences/50230.csv', 'indexedSentences/52266861.csv', 'indexedSentences/3225681.csv', 'indexedSentences/2659490.csv', 'indexedSentences/1515991.csv', 'indexedSentences/1497012.csv', 'indexedSentences/625857.csv', 'indexedSentences/1236563.csv']\n"
     ]
    }
   ],
   "source": [
    "folder = \"indexedSentences\"\n",
    "import glob\n",
    "files = set(glob.glob(folder + \"/*\"))\n",
    "print(len(files), \" files\" )\n",
    "import random\n",
    "samples = random.sample(files, 100)\n",
    "print(100, \" samples\" )\n",
    "print(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "88ccb4b0-a323-41cc-aa14-c28a74de4546",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "# Look for sentences matching any seed\n",
    "# Using Spacy\n",
    "# Install spaCy (run in terminal/prompt)\n",
    "#import sys\n",
    "#!{sys.executable} -m pip install spacy\n",
    "#\n",
    "# Download spaCy's  'en' Model\n",
    "#!{sys.executable} -m spacy download en\n",
    "\n",
    "#### Sentence -> lemmas -> match any seed\n",
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm', disable=['parser', 'ner'])\n",
    "sentence = \"The striped bats are hanging on their feet for best\"\n",
    "doc = nlp(sentence)\n",
    "print(\"hang\" in [token.lemma_ for token in doc])\n",
    "#\n",
    "# For each meetup type, load sentences matching any of the seed terms, in order to get a dictionary of types and prototype sentences.\n",
    "# nlp in scope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "974a66ba-74eb-4f33-bb57-b4bec988bcaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Music making': ['conduct', 'perform', 'join', 'produce', 'write', 'sing', 'play', 'song', 'record'], 'Business meeting': ['sign', 'agree', 'contract', 'commit', 'retire', 'career', 'hire', 'debut'], 'Personal life': ['bear', 'die', 'marry', 'divorce', 'adult', 'child', 'elder', 'young', 'father', 'mother', 'family'], 'Coincidence': ['meet', 'stumble', 'encounter', 'find', 'discover', 'trigger'], 'Public celebration': ['award', 'ceremony', 'marriage', 'funeral', 'public', 'celebration'], 'Education': ['learn', 'teach', 'mentor', 'degree', 'university', 'academia', 'conservatoire']}\n",
      "Music making <class 'list'>\n",
      "Business meeting <class 'list'>\n",
      "Personal life <class 'list'>\n",
      "Coincidence <class 'list'>\n",
      "Public celebration <class 'list'>\n",
      "Education <class 'list'>\n"
     ]
    }
   ],
   "source": [
    "# nlp is in scope\n",
    "\n",
    "# Clean seeds\n",
    "for mtype, mseeds in meetup_types.items():\n",
    "    doc = nlp(\" \".join(mseeds).lower())\n",
    "    meetup_types[mtype] = [token.lemma_ for token in doc]\n",
    "\n",
    "print(meetup_types)\n",
    "for mtype, mseeds in meetup_types.items():\n",
    "    print(mtype, type(mseeds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fe367ec3-8382-460b-8534-16dc1d2e2c40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2651\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "#sample_file = samples[0]\n",
    "\n",
    "prototypeSentences = []\n",
    "for sample_file in samples:\n",
    "    with open(sample_file) as csv_file:\n",
    "        csv_reader = csv.reader(csv_file, delimiter=',')\n",
    "        line_count = 0\n",
    "        for row in csv_reader:\n",
    "            if line_count == 0:\n",
    "                #print(f'Column names are {\", \".join(row)}')\n",
    "                line_count += 1\n",
    "            else:\n",
    "                line_count += 1\n",
    "                #\n",
    "                text = row[0]\n",
    "                sentence = row[1]\n",
    "                paragraph = row[2]\n",
    "                section = row[3]\n",
    "                wikiId = row[4]\n",
    "                doc = nlp(text)\n",
    "                terms = [ token.lemma_ for token in doc ]\n",
    "                candidateTypes = {}\n",
    "                include = False\n",
    "                for mtype, mseeds in meetup_types.items():\n",
    "                    matchSeed = set(mseeds).intersection(set(terms))\n",
    "                    candidateTypes[mtype] = len(matchSeed) > 0\n",
    "                    if candidateTypes[mtype]:\n",
    "                        include = True\n",
    "                data = {}\n",
    "                if include:\n",
    "                    data[\"sentences\"] = text\n",
    "                    data[\"sentenceIndex\"] = sentence\n",
    "                    data[\"paragraphIndex\"] = paragraph\n",
    "                    data[\"section\"] = section\n",
    "                    data[\"file\"] = sample_file\n",
    "                    data[\"wikiId\"] = wikiId\n",
    "                    for mtype, match in candidateTypes.items():\n",
    "                        data[mtype] = match\n",
    "                    #print(data)\n",
    "                    prototypeSentences.append(data)\n",
    "print( len(prototypeSentences) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d0a9bb3a-9c28-4c2d-b328-99f4b54d6ac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write prototypes to file\n",
    "columns = prototypeSentences[0].keys()\n",
    "\n",
    "with open(outputFile, 'w', newline='') as output_file:\n",
    "    dict_writer = csv.DictWriter(output_file,  fieldnames=columns)\n",
    "    dict_writer.writeheader()\n",
    "    dict_writer.writerows(prototypeSentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "70e98026-eb32-4735-8b2f-9847c4f2d94a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sentences': 'His band included trumpeters Dizzy Gillespie, Jonah Jones, and Adolphus \"Doc\" Cheatham, saxophonists Ben Webster and Leon \"Chu\" Berry, guitarist Danny Barker, bassist Milt Hinton, and drummer Cozy Cole.Calloway had several hit records in the 1930s and 1940s, becoming known as the \"Hi-de-ho\" man of jazz for his most famous song, \"Minnie the Moocher\", originally recorded in 1931.', 'sentenceIndex': '3', 'paragraphIndex': '0', 'section': 'N/A', 'file': 'indexedSentences/155965.csv', 'wikiId': '155965', 'Music making': True, 'Business meeting': False, 'Personal life': False, 'Coincidence': False, 'Public celebration': False, 'Education': False}\n",
      "{'sentences': 'His career saw renewed interest when he appeared in the 1980 film The Blues Brothers.', 'sentenceIndex': '8', 'paragraphIndex': '0', 'section': 'N/A', 'file': 'indexedSentences/155965.csv', 'wikiId': '155965', 'Music making': False, 'Business meeting': True, 'Personal life': False, 'Coincidence': False, 'Public celebration': False, 'Education': False}\n",
      "{'sentences': 'Calloway was the first African American musician to sell a million records from a single and to have a nationally syndicated radio show.', 'sentenceIndex': '0', 'paragraphIndex': '1', 'section': 'N/A', 'file': 'indexedSentences/155965.csv', 'wikiId': '155965', 'Music making': True, 'Business meeting': False, 'Personal life': False, 'Coincidence': False, 'Public celebration': False, 'Education': False}\n"
     ]
    }
   ],
   "source": [
    "# print(prototypeSentences[1])\n",
    "# print(prototypeSentences[2])\n",
    "# print(prototypeSentences[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "970b3693-153c-4043-94f4-cccdf5c44361",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the seed sentences as training set with a sentencebert based classifier\n",
    "# https://medium.com/dair-ai/tl-dr-sentencebert-8dec326daf4e\n",
    "# Models https://www.sbert.net/docs/pretrained_models.html\n",
    "\n",
    "from sentence_transformers import SentenceTransformer \n",
    "\n",
    "model = SentenceTransformer('all-mpnet-base-v2')\n",
    "#Sentences we want to encode. Example: \n",
    "sentence = ['This framework generates embeddings for each input sentence']\n",
    " \n",
    "#Sentences are encoded by calling model.encode() \n",
    "embedding = model.encode(sentence)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc-autonumbering": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
