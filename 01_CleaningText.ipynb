{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fcbd1ca2-2547-4d05-a0f1-8ffec77ac76c",
   "metadata": {},
   "source": [
    "# Cleaning text collected from Wikipedia"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "264ab62d-279f-4c24-9936-1fe670de65d8",
   "metadata": {},
   "source": [
    "### Cleaning blank lines, and information after === See also section ===\n",
    "### also adding indexes to sentences, paragraphs and sections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "175e8963-91f4-41cb-8056-dd8ed4e30861",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from _datetime import date\n",
    "import nltk.tokenize as nt\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6de88234-f035-4d38-807c-70f3637a33b7",
   "metadata": {},
   "source": [
    "### 1. Cleaning text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2311d18f-1af7-4d64-a329-c4587787de45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 1 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   file_name  1000 non-null   object\n",
      "dtypes: object(1)\n",
      "memory usage: 7.9+ KB\n"
     ]
    }
   ],
   "source": [
    "# Read all files in sample folder\n",
    "# return a list object of files in the given folder\n",
    "files_list = [f for f in os.listdir('sample_textFiles') if not f.startswith('.')]\n",
    "# parse to dataframe\n",
    "df_files = pd.DataFrame(files_list, columns=['file_name'])\n",
    "df_files.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3688c567-3ede-497f-92c4-86a6aca2bbad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_text(filename,folder):\n",
    "    fileObject = open(folder+filename, \"r\")\n",
    "    data = fileObject.readlines()\n",
    "    return data\n",
    "\n",
    "# save the file after cleaning\n",
    "def writeTextFile(directory, filename, content):\n",
    "    f = open(directory+filename, \"w\")\n",
    "    f.writelines(content)\n",
    "    f.close()\n",
    "\n",
    "# cleaning text, get rid of blank lines and section \"==See also\"\n",
    "def cleanText(text):\n",
    "    ctext=[]\n",
    "    for line in text:\n",
    "        if \"== See also ==\" in line:\n",
    "            break\n",
    "        if not len(line.strip()) < 1 :\n",
    "            ctext.append(line)\n",
    "    return ctext\n",
    "\n",
    "def identifySection(txt):\n",
    "    '''\n",
    "    args: text, the paragraph to identify\n",
    "    return: section and subsection\n",
    "    '''\n",
    "    typeSection = 0\n",
    "    if txt.startswith(\"==\", 0, 2):\n",
    "        typeSection = 1\n",
    "    if txt.startswith(\"===\", 0, 3):\n",
    "        typeSection = 2\n",
    "    \n",
    "    return typeSection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1ffce5d6-9e5a-42d5-8cdf-a7f42af244b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "\n",
    "for biography_file in df_files.itertuples():\n",
    "    # read text\n",
    "    text = read_text(biography_file.file_name,\"sample_textFiles/\")\n",
    "    # clean empty lines\n",
    "    clean_text= cleanText(text)\n",
    "    # print number of paragraphs\n",
    "    # print(len(clean_text))\n",
    "    # save the file after cleaning\n",
    "    writeTextFile('cleanText/', biography_file.file_name,clean_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "770be941-3602-4d09-b9c9-c82126789c2d",
   "metadata": {},
   "source": [
    "### 2. Adding index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b8d22c1a-9987-4e3e-b114-3f42c57d52ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def identifySection(txt):\n",
    "    '''\n",
    "    args: text, the paragraph to identify\n",
    "    return: section and subsection\n",
    "    '''\n",
    "    typeSection = 0\n",
    "    if txt.startswith(\"==\", 0, 2):\n",
    "        typeSection = 1\n",
    "    if txt.startswith(\"===\", 0, 3):\n",
    "        typeSection = 2\n",
    "    \n",
    "    return typeSection\n",
    "\n",
    "# used to extract the sections and subsections\n",
    "def setSection(biography_df):# row section\n",
    "    sectionTitle_list = []\n",
    "    lastTitle = \"\"\n",
    "    sectionTitle = \"\"\n",
    "    # for each paragraph in the dataframe\n",
    "    for prg in biography_df.itertuples():\n",
    "        #return the type of section: level 0, level 1 (belongs to previous section)\n",
    "        typeSection = identifySection(prg.paragraph)\n",
    "        if typeSection==0 and lastTitle == \"\":\n",
    "            sectionTitle = \"N/A\"\n",
    "        elif typeSection==1:\n",
    "            lastTitle=prg.paragraph.replace('\\n', '')\n",
    "            # sectionTitle = prg.paragraph\n",
    "            sectionTitle = lastTitle\n",
    "        elif typeSection==2:\n",
    "            sectionTitle = lastTitle+\" | \"+prg.paragraph.replace('\\n', '')\n",
    "        # add to a list\n",
    "        sectionTitle_list.append(sectionTitle)\n",
    "    return sectionTitle_list\n",
    "    # row subsection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "fab4c20e-8411-493e-b105-4eecbad67113",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Structure: biography as a collection sections, sections as a collection of paragraphs\n",
    "## and paragraphs as a collection of sentences\n",
    "# Biography <- Section (s) <- Paragraph(s) <- Sentence(s)\n",
    "for text_file_name in df_files.itertuples():\n",
    "    df_coded_result = pd.DataFrame()\n",
    "\n",
    "    #read text\n",
    "    text = read_text(text_file_name.file_name,\"cleanText/\")\n",
    "    biography_df = pd.DataFrame({'paragraph':text})\n",
    "    #index number\n",
    "    biography_df['paragraphIndex'] = list(range(len(biography_df)))\n",
    "    \n",
    "    section_list = setSection(biography_df)\n",
    "    #section name\n",
    "    biography_df['section'] = section_list\n",
    "    # save information\n",
    "    biography_df.to_csv('indexedParagraphs/'+text_file_name.file_name.replace(\".txt\",\"\")+'.csv',index=False)\n",
    "    \n",
    "    # for each paragraph in the biography\n",
    "    for paragraph_row in biography_df.itertuples():\n",
    "        # divide the paragraph into sentences\n",
    "        ss=nt.sent_tokenize(paragraph_row.paragraph)\n",
    "        biography_df_per_sent = pd.DataFrame({'sentences':ss})\n",
    "        # add an index for sentences\n",
    "        biography_df_per_sent['sentenceIndex'] = list(range(len(biography_df_per_sent)))\n",
    "        biography_df_per_sent['paragraphIndex'] = paragraph_row.paragraphIndex\n",
    "        biography_df_per_sent['section'] = paragraph_row.section\n",
    "        biography_df_per_sent['wikiId'] = text_file_name.file_name.replace(\".txt\",\"\")\n",
    "        \n",
    "        df_coded_result = df_coded_result.append(biography_df_per_sent)\n",
    "        \n",
    "    df_coded_result.to_csv('indexedSentences/'+text_file_name.file_name.replace(\".txt\",\"\")+'.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79980ed6-6487-4450-a850-9e337a45a218",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
