{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "03654570-a7a6-4652-89fc-851620e93ec7",
   "metadata": {},
   "source": [
    "# Meetup type: training of a classifier\n",
    "\n",
    "Approach:\n",
    "- Use dataset produced by `MeetupType_prototypeSentences`\n",
    "\n",
    "Problems:\n",
    "- Build a balanced training set\n",
    "- Compute F1 for each class not working at the moment\n",
    "- Repeat with larger set of prototype sentences (use 2 = 14447 items) - Done\n",
    "- Find metric to measure probabilistic predictions\n",
    "- Validate test set against all classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8fd3a1b5-280b-4a55-a945-a47c90ec694c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sklearn in ./.python3/lib/python3.8/site-packages (0.0)\n",
      "Requirement already satisfied: scikit-learn in ./.python3/lib/python3.8/site-packages (from sklearn) (1.0.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in ./.python3/lib/python3.8/site-packages (from scikit-learn->sklearn) (3.1.0)\n",
      "Requirement already satisfied: joblib>=0.11 in ./.python3/lib/python3.8/site-packages (from scikit-learn->sklearn) (1.1.0)\n",
      "Requirement already satisfied: numpy>=1.14.6 in ./.python3/lib/python3.8/site-packages (from scikit-learn->sklearn) (1.22.1)\n",
      "Requirement already satisfied: scipy>=1.1.0 in ./.python3/lib/python3.8/site-packages (from scikit-learn->sklearn) (1.8.0)\n",
      "\u001b[33mWARNING: You are using pip version 20.1.1; however, version 22.0.4 is available.\n",
      "You should consider upgrading via the '/Users/ed4565/Development/polifonia/meetups_pilot/.python3/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Requirement already satisfied: sentence_transformers in ./.python3/lib/python3.8/site-packages (2.2.0)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.6.0 in ./.python3/lib/python3.8/site-packages (from sentence_transformers) (4.16.2)\n",
      "Requirement already satisfied: tqdm in ./.python3/lib/python3.8/site-packages (from sentence_transformers) (4.62.3)\n",
      "Requirement already satisfied: torch>=1.6.0 in ./.python3/lib/python3.8/site-packages (from sentence_transformers) (1.10.2)\n",
      "Requirement already satisfied: torchvision in ./.python3/lib/python3.8/site-packages (from sentence_transformers) (0.11.3)\n",
      "Requirement already satisfied: numpy in ./.python3/lib/python3.8/site-packages (from sentence_transformers) (1.22.1)\n",
      "Requirement already satisfied: scikit-learn in ./.python3/lib/python3.8/site-packages (from sentence_transformers) (1.0.2)\n",
      "Requirement already satisfied: scipy in ./.python3/lib/python3.8/site-packages (from sentence_transformers) (1.8.0)\n",
      "Requirement already satisfied: nltk in ./.python3/lib/python3.8/site-packages (from sentence_transformers) (3.7)\n",
      "Requirement already satisfied: sentencepiece in ./.python3/lib/python3.8/site-packages (from sentence_transformers) (0.1.96)\n",
      "Requirement already satisfied: huggingface-hub in ./.python3/lib/python3.8/site-packages (from sentence_transformers) (0.4.0)\n",
      "Requirement already satisfied: packaging>=20.0 in ./.python3/lib/python3.8/site-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (21.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in ./.python3/lib/python3.8/site-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (6.0)\n",
      "Requirement already satisfied: sacremoses in ./.python3/lib/python3.8/site-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (0.0.47)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,>=0.10.1 in ./.python3/lib/python3.8/site-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (0.11.5)\n",
      "Requirement already satisfied: regex!=2019.12.17 in ./.python3/lib/python3.8/site-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (2022.1.18)\n",
      "Requirement already satisfied: requests in ./.python3/lib/python3.8/site-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (2.27.1)\n",
      "Requirement already satisfied: filelock in ./.python3/lib/python3.8/site-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (3.6.0)\n",
      "Requirement already satisfied: typing-extensions in ./.python3/lib/python3.8/site-packages (from torch>=1.6.0->sentence_transformers) (4.0.1)\n",
      "Requirement already satisfied: pillow!=8.3.0,>=5.3.0 in ./.python3/lib/python3.8/site-packages (from torchvision->sentence_transformers) (9.0.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in ./.python3/lib/python3.8/site-packages (from scikit-learn->sentence_transformers) (3.1.0)\n",
      "Requirement already satisfied: joblib>=0.11 in ./.python3/lib/python3.8/site-packages (from scikit-learn->sentence_transformers) (1.1.0)\n",
      "Requirement already satisfied: click in ./.python3/lib/python3.8/site-packages (from nltk->sentence_transformers) (8.0.3)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in ./.python3/lib/python3.8/site-packages (from packaging>=20.0->transformers<5.0.0,>=4.6.0->sentence_transformers) (3.0.7)\n",
      "Requirement already satisfied: six in ./.python3/lib/python3.8/site-packages (from sacremoses->transformers<5.0.0,>=4.6.0->sentence_transformers) (1.16.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.python3/lib/python3.8/site-packages (from requests->transformers<5.0.0,>=4.6.0->sentence_transformers) (2021.10.8)\n",
      "Requirement already satisfied: idna<4,>=2.5; python_version >= \"3\" in ./.python3/lib/python3.8/site-packages (from requests->transformers<5.0.0,>=4.6.0->sentence_transformers) (3.3)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0; python_version >= \"3\" in ./.python3/lib/python3.8/site-packages (from requests->transformers<5.0.0,>=4.6.0->sentence_transformers) (2.0.10)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in ./.python3/lib/python3.8/site-packages (from requests->transformers<5.0.0,>=4.6.0->sentence_transformers) (1.26.8)\n",
      "\u001b[33mWARNING: You are using pip version 20.1.1; however, version 22.0.4 is available.\n",
      "You should consider upgrading via the '/Users/ed4565/Development/polifonia/meetups_pilot/.python3/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "\u001b[31mERROR: Could not find a version that satisfies the requirement pickle (from versions: none)\u001b[0m\n",
      "\u001b[31mERROR: No matching distribution found for pickle\u001b[0m\n",
      "\u001b[33mWARNING: You are using pip version 20.1.1; however, version 22.0.4 is available.\n",
      "You should consider upgrading via the '/Users/ed4565/Development/polifonia/meetups_pilot/.python3/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Requirement already satisfied: pandas in ./.python3/lib/python3.8/site-packages (1.4.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in ./.python3/lib/python3.8/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: numpy>=1.18.5; platform_machine != \"aarch64\" and platform_machine != \"arm64\" and python_version < \"3.10\" in ./.python3/lib/python3.8/site-packages (from pandas) (1.22.1)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./.python3/lib/python3.8/site-packages (from pandas) (2021.3)\n",
      "Requirement already satisfied: six>=1.5 in ./.python3/lib/python3.8/site-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n",
      "\u001b[33mWARNING: You are using pip version 20.1.1; however, version 22.0.4 is available.\n",
      "You should consider upgrading via the '/Users/ed4565/Development/polifonia/meetups_pilot/.python3/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Requirement already satisfied: numpy in ./.python3/lib/python3.8/site-packages (1.22.1)\n",
      "\u001b[33mWARNING: You are using pip version 20.1.1; however, version 22.0.4 is available.\n",
      "You should consider upgrading via the '/Users/ed4565/Development/polifonia/meetups_pilot/.python3/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install sklearn\n",
    "!pip install sentence_transformers\n",
    "!pip install pickle\n",
    "!pip install pandas\n",
    "!pip install numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "17946792-69a7-4e64-873d-f0d4d842fd87",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputIndex = 2\n",
    "inputFile = 'meetupType/prototypeSentences_' + str(inputIndex) + '.csv'\n",
    "save_path = 'meetupType/models'\n",
    "save_models = True\n",
    "repeated_sample = False\n",
    "#emb_type = 'sbert' # sbert,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7a2fddf9-acc9-432c-91ad-6bdfc91a49bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import sklearn.metrics\n",
    "from sklearn import tree\n",
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7c471866-3281-4ad9-8dae-7480c5ebb192",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Education 629\n",
      "Coincidence 952\n",
      "Public celebration 1200\n",
      "Business meeting 2113\n",
      "Personal life 4074\n",
      "Music making 7172\n",
      "Producing 629 items per class\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "# XXX Work in progress\n",
    "# Build a balanced training set\n",
    "# sentences,sentenceIndex,paragraphIndex,section,file,wikiId,\n",
    "\n",
    "labels = ['Music making','Business meeting','Personal life','Coincidence','Public celebration','Education' ]            \n",
    "sentences_map = {}\n",
    "with open(inputFile) as csv_file:\n",
    "        csv_reader = csv.reader(csv_file, delimiter=',')\n",
    "        first = True\n",
    "        for row in csv_reader:\n",
    "            if first:\n",
    "                first = False\n",
    "                continue\n",
    "            s = row[0] # 6-12\n",
    "            for i in range(6,12):\n",
    "                if row[i] == 'True': # \n",
    "                    l = labels[i-6]\n",
    "                    if l not in sentences_map.keys():\n",
    "                        sentences_map[l] = []\n",
    "                    sentences_map[l].append(s)\n",
    "\n",
    "counts = {}\n",
    "for key in sentences_map.keys():\n",
    "    counts[key] = len(sentences_map[key])\n",
    "\n",
    "# Build the training set by selecting first sentences from low represented classes\n",
    "counts={k: v for k, v in sorted(counts.items(), key=lambda item: item[1])}\n",
    "for key in counts.keys():\n",
    "    print(key,counts[key])\n",
    "\n",
    "# TODO Build balanced training set\n",
    "items_per_class = next(iter(counts.values()))\n",
    "print('Producing ' + str(items_per_class) + ' items per class')\n",
    "#for key in counts.keys():\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8ece0f2e-5c66-48fe-8a73-985daa9b8088",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('He is best known for writing the Hymn to Liberty (Greek: Ὕμνος εις την Ἐλευθερίαν, Ýmnos eis tīn Eleutherían), which was set to music by Nikolaos Mantzaros and became the Greek and Cypriot national anthem in 1865 and 1966 respectively.',\n",
       "  'Music making'),\n",
       " ('He was the central figure of the Heptanese School of poetry, and is considered the national poet of Greece—not only because he wrote the national anthem, but also because he contributed to the preservation of earlier poetic tradition and highlighted its usefulness to modern literature.',\n",
       "  'Music making'),\n",
       " ('Born in Zakynthos in 1798, Dionysios Solomos was the illegitimate child of a wealthy count, Nikolaos Solomos, and his housekeeper, Angeliki Nikli.',\n",
       "  'Personal life'),\n",
       " (\"Nikolaos Solomos was of Cretan origin; his family were Cretan refugees who settled on Zakynthos in 1670 after Crete's conquest by the Ottoman Empire in 1669.\",\n",
       "  'Personal life'),\n",
       " ('It is possible that his mother Angeliki Nikli came from the region of Mani.',\n",
       "  'Personal life')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import csv\n",
    "# OLD method to build the train_test set\n",
    "# sentences,sentenceIndex,paragraphIndex,section,file,wikiId,\n",
    "\n",
    "labels = ['Music making','Business meeting','Personal life','Coincidence','Public celebration','Education' ]            \n",
    "sentences = []\n",
    "types = []\n",
    "count_added = {}\n",
    "for key in counts.keys():\n",
    "    count_added[key] = 0\n",
    "\n",
    "with open(inputFile) as csv_file:\n",
    "        csv_reader = csv.reader(csv_file, delimiter=',')\n",
    "        first = True\n",
    "        for row in csv_reader:\n",
    "            if first:\n",
    "                first = False\n",
    "                continue\n",
    "            s = row[0] # 6-11\n",
    "            for i in range(6,12):\n",
    "                if row[i] == 'True' and count_added[labels[i-6]] <= items_per_class: # \n",
    "                    sentences.append(s)\n",
    "                    types.append(labels[i-6])\n",
    "                    count_added[labels[i-6]] = 1 + count_added[labels[i-6]]\n",
    "                    if not repeated_sample:\n",
    "                        break\n",
    "\n",
    "list(zip(sentences, types))[:5]       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d86cd9a5-7050-4fd4-abd5-1138d81be9fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'Music making': 630, 'Personal life': 630, 'Coincidence': 630, 'Public celebration': 630, 'Business meeting': 630, 'Education': 581})\n"
     ]
    }
   ],
   "source": [
    "import collections\n",
    "counter=collections.Counter(types)\n",
    "print(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a354a27c-65a6-41a2-bc4d-ec3b53561672",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3731 3731\n",
      "['Romero died three days later leading to reports questioning if the film will ever be made.', 'In 1961, she made her Broadway  debut in How to Succeed in Business Without Really Trying, where she met choreographer Bob Fosse and his wife, Gwen Verdon.', 'He co-wrote the song \"It\\'s the Blues (No. 14 Blues)\" which was recorded in Detroit and released by Victor.', \"Euday Bowman's work is not public domain.\", 'Muhal Richard Abrams (born Richard Lewis Abrams; September 19, 1930 – October 29, 2017) was an American educator, administrator, composer, arranger, clarinetist, cellist, and jazz pianist in the free jazz medium.', 'Sheinberg is credited with discovering director Steven Spielberg.', 'Die Schachtel, Zeit C01Archives sauvées des eaux – Luc Ferrari with Otomo Yoshihide.', \"A talented musician, Heath won the college's organ scholarship in his first term (he had previously tried for the organ scholarships at St Catharine's College, Cambridge, and Keble College, Oxford) which enabled him to stay at the university for a fourth year; he eventually graduated with a Second Class Honours BA in Philosophy, Politics and Economics in 1939.\", \"(In 2016, Time magazine noted that Playing in the Dark was among Morrison's most-assigned texts on U.S. college campuses, together with several of her novels and her 1993 Nobel Prize lecture.)Before the third novel of the Beloved Trilogy was published, Morrison was awarded the Nobel Prize in Literature in 1993.\", 'Jester Hairston at Find a Grave'] ['Personal life', 'Coincidence', 'Music making', 'Public celebration', 'Personal life', 'Coincidence', 'Personal life', 'Education', 'Public celebration', 'Coincidence']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "print(len(sentences), len(types))\n",
    "S_train, S_test, y_train, y_test = train_test_split(sentences, types, train_size = 0.8, stratify = types)\n",
    "#list(zip(X, y))[:10]\n",
    "print(S_train[:10],y_train[:10])\n",
    "# 1 - lentgh 2651 2651"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b0562a3e-7df4-4137-9d6e-0c8440ee2752",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded in  7.749250255999982\n",
      "Train embeddings produced in  233.052718615\n",
      "Train embeddings produced in  58.33115924499998\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "# Using the seed sentences as training set with a sentencebert based classifier\n",
    "# https://medium.com/dair-ai/tl-dr-sentencebert-8dec326daf4e\n",
    "# Models https://www.sbert.net/docs/pretrained_models.html\n",
    "# SBERT\n",
    "from sentence_transformers import SentenceTransformer \n",
    "t0 = time.monotonic()\n",
    "model = SentenceTransformer('all-mpnet-base-v2')\n",
    "t1 = time.monotonic()\n",
    "print('Model loaded in ', t1 - t0)\n",
    "#Sentences are encoded by calling model.encode() \n",
    "X_train = model.encode(S_train)\n",
    "t2 = time.monotonic()\n",
    "print('Train embeddings produced in ', t2 - t1)\n",
    "X_test = model.encode(S_test)\n",
    "t3 = time.monotonic()\n",
    "print('Train embeddings produced in ', t3 - t2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3c1fe0df-94dc-418c-986e-eb5f14fd2a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, random_state=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "725bcc2e-1023-41f2-9ef1-2325e0e0a9a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "import sklearn\n",
    "import pickle\n",
    "# Precision, Recall, F1 and Matthews' Correlation\n",
    "# sklearn.metrics.matthews_corrcoef(y_true, y_pred, *, sample_weight=None)\n",
    "def getAccuracy(y_test, predictions):\n",
    "    return sklearn.metrics.accuracy_score(y_test, predictions, normalize=True, sample_weight=None)\n",
    "\n",
    "def getF1(y_test, predictions):\n",
    "    f1 = []\n",
    "    for l in sorted(set(y_test)):\n",
    "        print(\"F1 for label \",l)\n",
    "        f1.append(sklearn.metrics.f1_score(y_test, predictions, labels=[l], average=None)[0])\n",
    "        #f1.append(sklearn.metrics.f1_score(y_test, predictions, average='macro'))\n",
    "    return f1\n",
    "\n",
    "def getMatthews(y_test,predictions):\n",
    "    return sklearn.metrics.matthews_corrcoef(y_test,predictions)\n",
    "\n",
    "\n",
    "def save_model(clf, path):\n",
    "    fname = type(clf).__name__ + '_' + str(inputIndex) + '.clf'\n",
    "    pickle.dump(clf, open(path + '/' + fname, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "acc0d561-c855-43e8-91af-17e2d142a6b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 for label  Business meeting\n",
      "F1 for label  Coincidence\n",
      "F1 for label  Education\n",
      "F1 for label  Music making\n",
      "F1 for label  Personal life\n",
      "F1 for label  Public celebration\n"
     ]
    }
   ],
   "source": [
    "# MLPClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "#print(y_test)\n",
    "clf = MLPClassifier(random_state=1, max_iter=600)\n",
    "clf.fit(X_train, y_train)\n",
    "MLPClassifierPredictions = clf.predict(X_test)\n",
    "MLPClassifierAccuracy = getAccuracy(y_test, MLPClassifierPredictions)\n",
    "MLPClassifierF1 = getF1(y_test, MLPClassifierPredictions)\n",
    "\n",
    "MLPClassifierMatthews = getMatthews(y_test, MLPClassifierPredictions)\n",
    "results.append([\"MLPClassifier\", MLPClassifierAccuracy, MLPClassifierMatthews]+MLPClassifierF1)\n",
    "if(save_models):\n",
    "    save_model(clf, save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "df468044-d3ea-465a-898f-e81404f25ad8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Approach  Accuracy  Matthews  Business meeting  Coincidence  \\\n",
      "0  MLPClassifier     0.707     0.648             0.724        0.675   \n",
      "\n",
      "   Education  Music making  Personal life  Public celebration  \n",
      "0      0.762         0.628          0.744               0.707  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "print(pd.DataFrame(results, columns=[\"Approach\", \"Accuracy\", \"Matthews\"]+sorted(set(y_test))))\n",
    "\n",
    "# PAST RESULTS\n",
    "# Approach  Accuracy  Matthews  Business meeting  Coincidence  \\\n",
    "# 0  MLPClassifier   0.63606  0.464063          0.493197     0.493197   \n",
    "\n",
    "#    Education  Music making  Personal life  Public celebration  \n",
    "# 0   0.493197      0.493197       0.493197            0.493197"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c1f03a7-b9a3-492c-b1d9-7edbadaf0fb4",
   "metadata": {},
   "source": [
    "## Note\n",
    "The test results include the labels in a different order than the one in the training set (they are sorted).\n",
    "The classifier generates scores considering the labels as ordered in the training set file:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "22d9c9eb-5cdb-4611-bff5-1550bea944a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                            Sentence          Test_class  \\\n",
      "0  Goldsmith was honoured with the 15th Music Ind...  Public celebration   \n",
      "1  In 1940, Vian met Michelle Léglise, who became...         Coincidence   \n",
      "2  He switches ragas with ease, and sings complex...        Music making   \n",
      "3  By 1944, Skelton was engaged to actress Muriel...       Personal life   \n",
      "4  The re-recording peaked at No. 9 one week to t...        Music making   \n",
      "5  1968: Peter Thomas, Ika Schafheitlin, Helmuth ...       Personal life   \n",
      "6  John Herbert Gleason was born on February 26, ...       Personal life   \n",
      "7  Max had also been commissioned to design bilin...    Business meeting   \n",
      "8                   He has been married three times.       Personal life   \n",
      "9  During the 1960s, as the public taste shifted ...         Coincidence   \n",
      "\n",
      "   Business meeting  Coincidence  Education  Music making  Personal life  \\\n",
      "0             0.004        0.000      0.000         0.000          0.000   \n",
      "1             0.000        0.052      0.000         0.000          0.948   \n",
      "2             0.404        0.005      0.232         0.351          0.007   \n",
      "3             0.000        0.000      0.000         0.000          0.994   \n",
      "4             0.975        0.000      0.000         0.001          0.000   \n",
      "5             0.000        0.000      0.000         0.000          1.000   \n",
      "6             0.000        0.000      0.000         0.000          0.999   \n",
      "7             1.000        0.000      0.000         0.000          0.000   \n",
      "8             0.000        0.000      0.000         0.000          0.983   \n",
      "9             0.033        0.964      0.000         0.000          0.000   \n",
      "\n",
      "   Public celebration  \n",
      "0               0.996  \n",
      "1               0.000  \n",
      "2               0.000  \n",
      "3               0.005  \n",
      "4               0.024  \n",
      "5               0.000  \n",
      "6               0.001  \n",
      "7               0.000  \n",
      "8               0.017  \n",
      "9               0.004  \n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "proba = clf.predict_proba(X_test)\n",
    "#print(zip(proba[:10]))\n",
    "output_proba = []\n",
    "for index, item in enumerate(S_test):\n",
    "    #print(ix[0][0],proba[index])\n",
    "    #print([sentences[int(ix[0][0])]], proba[index])\n",
    "    #print(item,y_test[index])\n",
    "    output_proba.append([item, y_test[index]] + list(proba[index]))\n",
    "    #break\n",
    "\n",
    "#print(senten1)\n",
    "pd.set_option('display.float_format', lambda x: '%.3f' % x)\n",
    "df = pd.DataFrame(output_proba, columns=['Sentence','Test_class']+sorted(labels))\n",
    "print(df[:10])\n",
    "df.to_csv(save_path + '/MLPClassifier_test_results_' + str(inputIndex) + '.csv', float_format = '%.6f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87c4f746-c653-49a1-8ebf-f82def6a4d53",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c196c671-37d3-4410-8abc-812337c67506",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
