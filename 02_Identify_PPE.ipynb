{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c4921149-8064-4594-8b85-babce5c8d76a",
   "metadata": {},
   "source": [
    "### identify PPE: Places, Persons, Events"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e76383e8-c8d5-4111-95a9-9c01e9a40e5a",
   "metadata": {},
   "source": [
    "### 1. Identify Places, Persons, Events using DBpedia Spotlight\n",
    "### 2. Identify time entities using NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8a0900ea-2fc1-4e27-8259-cc2b432db572",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For DBpedia spotlight, PPE entities\n",
    "import requests\n",
    "import pycurl\n",
    "from urllib.request import urlopen\n",
    "from urllib.parse import quote\n",
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "from _datetime import date\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e7b04f3c-1504-4d1f-8069-7e7d31a4aec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For nltk time entities\n",
    "# time entity\n",
    "import nltk.tokenize as nt\n",
    "import nltk\n",
    "from nltk.tag import pos_tag\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk import Tree\n",
    "\n",
    "# if not installed\n",
    "# nltk.download('averaged_perceptron_tagger')\n",
    "# nltk.download('maxent_ne_chunker')\n",
    "# nltk.download('words')\n",
    "# nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "de1ca3a4-8c9f-459f-839d-b696f941c7bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1002 entries, 0 to 1001\n",
      "Data columns (total 1 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   file_name  1002 non-null   object\n",
      "dtypes: object(1)\n",
      "memory usage: 8.0+ KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000228.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100273.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100487.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10085.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1009725.csv</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     file_name\n",
       "0  1000228.csv\n",
       "1   100273.csv\n",
       "2   100487.csv\n",
       "3    10085.csv\n",
       "4  1009725.csv"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reading every CSV with indexed sentences\n",
    "# return a list object of files in the given folder\n",
    "files_list = [f for f in os.listdir('indexedSentences') if not f.startswith('.')]\n",
    "# parse to dataframe\n",
    "df_files = pd.DataFrame(files_list, columns=['file_name'])\n",
    "# df_files = df_files.query(\"file_name=='10085.csv'\")\n",
    "\n",
    "df_files.info()\n",
    "df_files.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6bfb2ab8-9aeb-434b-a401-04a73eff7b92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 0 entries\n",
      "Data columns (total 1 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   file_name  0 non-null      object\n",
      "dtypes: object(1)\n",
      "memory usage: 0.0+ bytes\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [file_name]\n",
       "Index: []"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extract only the ones that do not exist in folder\n",
    "files_list = [f for f in os.listdir('extractedEntities') if not f.startswith('.')]\n",
    "# parse to dataframe\n",
    "df_query = pd.DataFrame(files_list, columns=['file_name'])\n",
    "df_result = df_files[~df_files['file_name'].isin(df_query['file_name'])]\n",
    "df_files = df_result\n",
    "df_files.info()\n",
    "df_files.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bfaca6f-7b2c-4078-a7b6-615e2a551cda",
   "metadata": {},
   "source": [
    "## 1. Identify PPE using DBpedia Spotlight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "33917612-c4ef-4232-b4c7-74aef72d5b8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using DBPedia spotlight to search for entities\n",
    "# URL for local installation of DBpedia spotlight\n",
    "# urlAnnotation = 'http://dbpedia-spotlight.en:80/rest/annotate/'\n",
    "urlAnnotation = 'https://whise.kmi.open.ac.uk/rest/annotate'\n",
    "\n",
    "# setting headers and parameters not using DBpedia categories\n",
    "def setDbPediaAnnotationServiceParameters(text):\n",
    "    \"\"\" Se parameters for querying Dbpedia\n",
    "    args: text - text to be analysed\n",
    "    return: headers\n",
    "            params\n",
    "    \"\"\"\n",
    "    headers = {\n",
    "        'Accept':'application/json',\n",
    "        \"content-type\":\"application/x-www-form-urlencoded\"\n",
    "    }\n",
    "\n",
    "    params = {\n",
    "        'confidence': '0.4',\n",
    "        \"text\":text,\n",
    "    }\n",
    "    return headers, params\n",
    "\n",
    "# setting headers and parameters, filtering by categories\n",
    "def setDbPediaAnnotationServiceParametersTypes(text,types):\n",
    "    \"\"\" Se parameters for querying Dbpedia\n",
    "    args: text - text to be analysed\n",
    "        types: different categories of entities\n",
    "    return: headers\n",
    "            params\n",
    "    \"\"\"\n",
    "    headers = {\n",
    "        'Accept':'application/json',\n",
    "        \"content-type\":\"application/x-www-form-urlencoded\"\n",
    "    }\n",
    "\n",
    "    params = {\n",
    "        'types' : types,\n",
    "        'confidence': '0.35',\n",
    "        \"text\":text,\n",
    "    }\n",
    "    return headers, params\n",
    "\n",
    "# return response in JSON format\n",
    "def queryDBPediaAnnotation(url,header,params):\n",
    "    try:\n",
    "        response = requests.post(url,headers=header, params=params).json()\n",
    "        \n",
    "    except Exception as ex:\n",
    "        if hasattr(ex, 'message'):\n",
    "            print(ex.message)\n",
    "        else:\n",
    "            print(ex)\n",
    "        raise Exception(ex)\n",
    "    # finally:\n",
    "        # print(response)\n",
    "\n",
    "    return response\n",
    "\n",
    "def executeQueryDbpedia(q, f='application/json'):\n",
    "    epr = \"http://dbpedia.org/sparql\"\n",
    "    try:\n",
    "        params = {'query': q}\n",
    "        resp = requests.get(epr, params=params, headers={'Accept': f})\n",
    "    #    return resp.text\n",
    "        return resp\n",
    "    except Exception as e:\n",
    "        print(e, file=sys.stdout)\n",
    "        raise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa431c11-e50f-4b89-9dc6-c326fb2e5719",
   "metadata": {},
   "source": [
    "## 1. Extract entities: People, places"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "01d49591-ee8a-45e1-ac0d-dafbdc450ea7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000228.csv\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'setDbPediaAnnotationServiceParameters' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_32/512359296.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0msentence_row\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbiography_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitertuples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0;31m## send sentence text and return params for query\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0mhdrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msetDbPediaAnnotationServiceParameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence_row\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0;31m# obtain response using DBpedia spotlight\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'setDbPediaAnnotationServiceParameters' is not defined"
     ]
    }
   ],
   "source": [
    "# 1. Extract People and Places entities\n",
    "entitiyTypes = ['DBpedia:Person','DBpedia:MusicalArtist','DBpedia:Place','DBpedia:SocietalEvent']\n",
    "\n",
    "# Count the number of files read to include breaks\n",
    "count = 0\n",
    "for file_name in df_files.itertuples():\n",
    "    count +=1\n",
    "    # start = time.time()\n",
    "    print(file_name.file_name)\n",
    "    # Read file with segmented sentences\n",
    "    biography_df = pd.read_csv('indexedSentences/'+file_name.file_name)\n",
    "    df_entities = pd.DataFrame()\n",
    "    \n",
    "    # for each sentence in each biography\n",
    "    for sentence_row in biography_df.itertuples():\n",
    "        ## send sentence text and return params for query\n",
    "        hdrs, prms = setDbPediaAnnotationServiceParameters(sentence_row.sentences)\n",
    "        try:\n",
    "            # obtain response using DBpedia spotlight\n",
    "            responseJSON = queryDBPediaAnnotation(urlAnnotation,hdrs,prms)\n",
    "            # UPDATE: save responses from DBP Spotlight\n",
    "            if 'Resources' in responseJSON:\n",
    "                file_exists = os.path.isfile('cacheSpotlightResponse/'+file_name.file_name)\n",
    "                df_resources = pd.DataFrame.from_dict(responseJSON['Resources'])\n",
    "                df_resources['sentence']=sentence_row.sentences\n",
    "                df_resources['sentenceIndex']=sentence_row.sentenceIndex\n",
    "                df_resources['paragraphIndex'] = sentence_row.paragraphIndex\n",
    "                df_resources['section'] = sentence_row.section\n",
    "                if not file_exists:\n",
    "                    df_resources.to_csv('cacheSpotlightResponse/'+file_name.file_name,index=False)\n",
    "                else:\n",
    "                    df_resources.to_csv('cacheSpotlightResponse/'+file_name.file_name,mode='a',index=False,header=False)\n",
    "                \n",
    "        except Exception as ex:\n",
    "            print(\"****\")\n",
    "            if hasattr(ex, 'message'):\n",
    "                print(ex.message)\n",
    "            else:\n",
    "                print(ex)\n",
    "\n",
    "        # if entities People, places, events using spotlight\n",
    "        if 'Resources' in responseJSON:\n",
    "            # parse response to a dataframe\n",
    "            df_resources = pd.DataFrame.from_dict(responseJSON['Resources'])\n",
    "            df_resources.rename(columns={'@URI':'URI','@types':'types','@surfaceForm':'surfaceForm','@support':'support','@offset':'offset','@similarityScore':'similarityScore',\n",
    "                                        '@percentageOfSecondRank':'percentageOfSecondRank'}, inplace=True)\n",
    "            \n",
    "            # filter only rows for entities with a category\n",
    "            df = df_resources[~df_resources['types'].isna()].copy()\n",
    "\n",
    "            # UPDATE: improving entity recognition\n",
    "            df_result = pd.DataFrame()\n",
    "            #\n",
    "            \n",
    "            if not df.empty:\n",
    "                #df_result = pd.DataFrame()\n",
    "                # assign the type of entity found, according to the categories\n",
    "                for entity in entitiyTypes:\n",
    "                    df_temp = df[df['types'].str.contains(entity)].copy()\n",
    "                    \n",
    "                    if not df_temp.empty:\n",
    "                        # df_temp.head(2)\n",
    "                        if entity == 'DBpedia:Person' or entity == 'DBpedia:MusicalArtist':\n",
    "                            df_temp['entType'] = 'person'\n",
    "                        elif entity == 'DBpedia:Place':\n",
    "                            df_temp['entType'] = 'place'\n",
    "                        elif entity == 'DBpedia:SocietalEvent' or entity == 'DBpedia:Event':\n",
    "                            df_temp['entType'] = 'event'\n",
    "                            \n",
    "                        df_result = df_result.append(df_temp)\n",
    "                        \n",
    "            # UPDATE:\n",
    "            # Adding process to query entities without the type\n",
    "            # filter only rows without category\n",
    "            df = df_resources.loc[df_resources['types'] == ''] \n",
    "            if not df.empty:\n",
    "                for item in df.itertuples():\n",
    "                    uri = item.URI\n",
    "                    query_text = \"SELECT * WHERE { <\" + uri + \"> <http://www.w3.org/1999/02/22-rdf-syntax-ns#type>  ?o }\"\n",
    "                    # Execute query against sparql endpoint, query types\n",
    "                    results = executeQueryDbpedia(query_text).json()\n",
    "                    \n",
    "                    # if query returns a response\n",
    "                    if 'results' in results:\n",
    "                        df_none = pd.DataFrame.from_dict(results['results']['bindings'])\n",
    "\n",
    "                        for item in df_none.itertuples():\n",
    "                            df_temp = pd.DataFrame()\n",
    "                            # find types Place and Person\n",
    "                            if 'http://dbpedia.org/ontology/Place' == item.o['value']:\n",
    "                                df_result = df_result.append({'entType':'place','URI':uri,'types':item.o['value']}, ignore_index=True)\n",
    "                            elif 'http://dbpedia.org/ontology/Person' == item.o['value']:\n",
    "                                df_result = df_result.append({'entType':'person','URI':uri,'types':item.o['value']}, ignore_index=True)\n",
    "            #\n",
    "            if not df_result.empty:\n",
    "                df_result['sentence']=sentence_row.sentences\n",
    "                df_result['sentenceIndex']=sentence_row.sentenceIndex\n",
    "                df_result['paragraphIndex'] = sentence_row.paragraphIndex\n",
    "                df_result['section'] = sentence_row.section\n",
    "                df_result.rename(columns = {'surfaceForm':'entity'},inplace = True)\n",
    "                \n",
    "                df_entities = df_entities.append(df_result)\n",
    "\n",
    "    # append time\n",
    "    df_entities['wikiPageID'] = sentence_row.wikiId\n",
    "    df_entities.to_csv('extractedEntitiesPersonPlaceOnly/'+file_name.file_name,index=False)\n",
    "    # end = time.time()\n",
    "    # print(\"The time of execution of above program is :\", end-start)\n",
    "    time.sleep(1)\n",
    "    \n",
    "    if (count % 50) == 0:\n",
    "        time.sleep(120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "aed0d4ab-7cae-46ac-805c-d6366be2f658",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "+ = match 1 or more\n",
    "? = match 0 or 1 repetitions.\n",
    "* = match 0 or MORE repetitions\t  \n",
    ". = Any character except a new line\n",
    "CD\tcardinal digit\n",
    "DT\tdeterminer\n",
    "NN\tnoun, singular 'desk'\n",
    "NNS\tnoun plural\t'desks'\n",
    "NNP\tproper noun, singular\t'Harrison'\n",
    "NNPS\tproper noun, plural\t'Americans'\n",
    "IN\tpreposition/subordinating conjunction\n",
    "RB\tadverb\tvery, silently,\n",
    "RBR\tadverb, comparative\tbetter\n",
    "RBS\tadverb, superlative\tbest\n",
    "\"\"\"\n",
    "def set_pattern_time():\n",
    "    pattern = r\"\"\"DT1: #dates, time point\n",
    "    {<CD?><NNP|CD?><CD?>} #complete dates Eg. 23 January 1983\n",
    "    {<NNP?><CD?><,?><CD?>} # December 13, 2000\n",
    "    {<CD?></><CD?></><CD?>} #complete dates 23/02/2021\n",
    "    {<CD?><-><CD?><-><CD?>} #complete dates 23-02-2021\n",
    "    HO: # HOURS\n",
    "    {<CD>+<NN>+} # hour only\n",
    "    RN: # range \n",
    "    {<IN><CD>+<IN|TO|CC>+<CD>+} # between YYYY and <> YYYY, from 1938 to 1939\n",
    "    DT2: #date from explicit, to implicit DT2 [('each', 'DT'), ('one', 'CD')]\n",
    "    {<IN>+<DT>?<\\d>} # \"in XXXX\" (year)\n",
    "    <\\W?>{<CD>}<\\W?> # year in between special characters\n",
    "    {<NNP><CD>} #incomplete date January 2003, Fall 1994\n",
    "    {<IN>+<DT>+<CD>+} # years dt the 1990s, leukemia in 1996, age of 43,the 1990s\n",
    "    {<NN>+<IN|DT>+<CD>} # years dt the 1990s, leukemia in 1996, age of 43,the 1990s\n",
    "    {<CD><IN>} # 1984 novel,1954–58\n",
    "    DT3:\n",
    "    <DT>+{<CD>}\n",
    "    REF: # references, implicit\n",
    "    {<IN>+<NN>+<CD>+} # by age 43\n",
    "    {<NN><IN><CD>} # Eg. fall/winter of 1345, age of 43\n",
    "    <NN>{<DT>+<CD>} # Eg. fall/winter of 1345, age of 43\n",
    "    \"\"\"\n",
    "    return pattern"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5370efe2-dfde-46fa-9884-14051da03a4f",
   "metadata": {},
   "source": [
    "## 2. Extract time expressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "e68abe2d-9c07-4c59-a7aa-d6bf25dc4908",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000228.csv\n",
      "100273.csv\n",
      "100487.csv\n",
      "10085.csv\n",
      "1009725.csv\n",
      "1010510.csv\n",
      "1010943.csv\n",
      "10120.csv\n",
      "1013900.csv\n",
      "1022191.csv\n",
      "1023303.csv\n",
      "1024347.csv\n",
      "1028178.csv\n",
      "103549.csv\n",
      "103566.csv\n",
      "1035724.csv\n",
      "1043762.csv\n",
      "1047779.csv\n",
      "1048151.csv\n",
      "1048172.csv\n",
      "1049483.csv\n",
      "1052490.csv\n",
      "1056463.csv\n",
      "105767.csv\n",
      "1058567.csv\n",
      "1059399.csv\n",
      "106366.csv\n",
      "1065532.csv\n",
      "1065581.csv\n",
      "10671.csv\n",
      "1068160.csv\n",
      "1070521.csv\n",
      "1073691.csv\n",
      "1077508.csv\n",
      "1081839.csv\n",
      "1084179.csv\n",
      "1089533.csv\n",
      "1092607.csv\n",
      "1093129.csv\n",
      "1097923.csv\n",
      "1098118.csv\n",
      "1103482.csv\n",
      "1107893.csv\n",
      "1111730.csv\n",
      "1113259.csv\n",
      "1113588.csv\n",
      "1115155.csv\n",
      "1118112.csv\n",
      "1127222.csv\n",
      "1129635.csv\n",
      "113049.csv\n",
      "113560.csv\n",
      "1142145.csv\n",
      "1147577.csv\n",
      "1148248.csv\n",
      "1150533.csv\n",
      "1151374.csv\n",
      "1153177.csv\n",
      "1164879.csv\n",
      "1174545.csv\n",
      "1174834.csv\n",
      "1175222.csv\n",
      "1178548.csv\n",
      "1181295.csv\n",
      "1181499.csv\n",
      "1186480.csv\n",
      "1188821.csv\n",
      "1189627.csv\n",
      "1194878.csv\n",
      "1195717.csv\n",
      "1196793.csv\n",
      "1205991.csv\n",
      "1207899.csv\n",
      "1209484.csv\n",
      "1209685.csv\n",
      "1213916.csv\n",
      "1215145.csv\n",
      "1228021.csv\n",
      "1232492.csv\n",
      "1234422.csv\n",
      "1234606.csv\n",
      "1236563.csv\n",
      "1239372.csv\n",
      "1244554.csv\n",
      "1245489.csv\n",
      "125311.csv\n",
      "1253783.csv\n",
      "1253793.csv\n",
      "1254002.csv\n",
      "1254005.csv\n",
      "1261779.csv\n",
      "1263963.csv\n",
      "1265845.csv\n",
      "1271437.csv\n",
      "1271796.csv\n",
      "1272132.csv\n",
      "1275454.csv\n",
      "1277042.csv\n",
      "1285387.csv\n",
      "1291198.csv\n",
      "1291515.csv\n",
      "129194.csv\n",
      "12945.csv\n",
      "1296456.csv\n",
      "1302505.csv\n",
      "1303365.csv\n",
      "1310858.csv\n",
      "1320240.csv\n",
      "1321577.csv\n",
      "1322881.csv\n",
      "1323952.csv\n",
      "1324135.csv\n",
      "1338168.csv\n",
      "1338619.csv\n",
      "1341923.csv\n",
      "1343880.csv\n",
      "1346743.csv\n",
      "1351998.csv\n",
      "1354212.csv\n",
      "1354646.csv\n",
      "1354841.csv\n",
      "1354864.csv\n",
      "1359293.csv\n",
      "1359335.csv\n",
      "1372235.csv\n",
      "1372632.csv\n",
      "1373444.csv\n",
      "137869.csv\n",
      "1384081.csv\n",
      "1391973.csv\n",
      "1392224.csv\n",
      "1394504.csv\n",
      "1396921.csv\n",
      "1399340.csv\n",
      "1400829.csv\n",
      "1403521.csv\n",
      "140417.csv\n",
      "140632.csv\n",
      "1407035.csv\n",
      "1409780.csv\n",
      "1410438.csv\n",
      "1413284.csv\n",
      "141330.csv\n",
      "1413746.csv\n",
      "1413790.csv\n",
      "1417421.csv\n",
      "1420817.csv\n",
      "1422240.csv\n",
      "1425206.csv\n",
      "1429918.csv\n",
      "143114.csv\n",
      "143160.csv\n",
      "1433271.csv\n",
      "1433411.csv\n",
      "1439437.csv\n",
      "1441938.csv\n",
      "144196.csv\n",
      "144624.csv\n",
      "1451518.csv\n",
      "1453044.csv\n",
      "1456343.csv\n",
      "145644.csv\n",
      "1469838.csv\n",
      "1470710.csv\n",
      "1470994.csv\n",
      "1471350.csv\n",
      "147308.csv\n",
      "1474046.csv\n",
      "1476033.csv\n",
      "1477038.csv\n",
      "1479807.csv\n",
      "1491559.csv\n",
      "1495782.csv\n",
      "1497012.csv\n",
      "149935.csv\n",
      "150095.csv\n",
      "1503167.csv\n",
      "1505727.csv\n",
      "1515991.csv\n",
      "1517676.csv\n",
      "1517721.csv\n",
      "1520949.csv\n",
      "152097.csv\n",
      "152195.csv\n",
      "152557.csv\n",
      "1529361.csv\n",
      "1530722.csv\n",
      "1531242.csv\n",
      "1540074.csv\n",
      "154038.csv\n",
      "154191.csv\n",
      "1547707.csv\n",
      "154959.csv\n",
      "1549850.csv\n",
      "155107.csv\n",
      "1551249.csv\n",
      "1551347.csv\n",
      "155965.csv\n",
      "1560872.csv\n",
      "1561641.csv\n",
      "1561694.csv\n",
      "1562492.csv\n",
      "156414.csv\n",
      "1566844.csv\n",
      "1566892.csv\n",
      "1569660.csv\n",
      "1571869.csv\n",
      "15766.csv\n",
      "1578500.csv\n",
      "1588479.csv\n",
      "1593203.csv\n",
      "1593504.csv\n",
      "1595398.csv\n",
      "1597545.csv\n",
      "1598663.csv\n",
      "1599087.csv\n",
      "1600435.csv\n",
      "1605379.csv\n",
      "162348.csv\n",
      "164398.csv\n",
      "164481.csv\n",
      "164576.csv\n",
      "165113.csv\n",
      "165697.csv\n",
      "165726.csv\n",
      "16578.csv\n",
      "166331.csv\n",
      "166529.csv\n",
      "167790.csv\n",
      "167975.csv\n",
      "168478.csv\n",
      "168565.csv\n",
      "169917.csv\n",
      "170021.csv\n",
      "1706070.csv\n",
      "1709886.csv\n",
      "1709914.csv\n",
      "171050.csv\n",
      "1714150.csv\n",
      "1714891.csv\n",
      "172563.csv\n",
      "1730644.csv\n",
      "173225.csv\n",
      "1733334.csv\n",
      "1733863.csv\n",
      "1745996.csv\n",
      "175068.csv\n",
      "1753869.csv\n",
      "1758122.csv\n",
      "1758540.csv\n",
      "176912.csv\n",
      "177220.csv\n",
      "177293.csv\n",
      "1774359.csv\n",
      "177771.csv\n",
      "1786533.csv\n",
      "1787782.csv\n",
      "1788051.csv\n",
      "1790137.csv\n",
      "17902.csv\n",
      "1790603.csv\n",
      "1790990.csv\n",
      "1798531.csv\n",
      "1799252.csv\n",
      "1808209.csv\n",
      "1813252.csv\n",
      "181946.csv\n",
      "181985.csv\n",
      "181998.csv\n",
      "1823012.csv\n",
      "1826921.csv\n",
      "1828359.csv\n",
      "18434.csv\n",
      "185085.csv\n",
      "1850886.csv\n",
      "185202.csv\n",
      "18571.csv\n",
      "186175.csv\n",
      "1869640.csv\n",
      "1870977.csv\n",
      "1875304.csv\n",
      "1876457.csv\n",
      "1882145.csv\n",
      "1883095.csv\n",
      "188533.csv\n",
      "189182.csv\n",
      "18995.csv\n",
      "1913885.csv\n",
      "1914666.csv\n",
      "192024.csv\n",
      "192586.csv\n",
      "192739.csv\n",
      "19318.csv\n",
      "194614.csv\n",
      "194903.csv\n",
      "196217.csv\n",
      "198362.csv\n",
      "20215.csv\n",
      "20405.csv\n",
      "20484.csv\n",
      "205508.csv\n",
      "205720.csv\n",
      "205811.csv\n",
      "207769.csv\n",
      "208803.csv\n",
      "208956.csv\n",
      "209161.csv\n",
      "209276.csv\n",
      "211626.csv\n",
      "214233.csv\n",
      "215098.csv\n",
      "220271.csv\n",
      "221191.csv\n",
      "221558.csv\n",
      "222192.csv\n",
      "222210.csv\n",
      "2232977.csv\n",
      "2233161.csv\n",
      "223497.csv\n",
      "2236628.csv\n",
      "2253021.csv\n",
      "226142.csv\n",
      "226445.csv\n",
      "2266591.csv\n",
      "2269540.csv\n",
      "2278498.csv\n",
      "2281945.csv\n",
      "2284844.csv\n",
      "2290176.csv\n",
      "2296195.csv\n",
      "2296293.csv\n",
      "2307312.csv\n",
      "2308152.csv\n",
      "2317280.csv\n",
      "2320846.csv\n",
      "2322673.csv\n",
      "232719.csv\n",
      "2327936.csv\n",
      "2330834.csv\n",
      "2334176.csv\n",
      "2334505.csv\n",
      "2335672.csv\n",
      "2341385.csv\n",
      "2343819.csv\n",
      "2344136.csv\n",
      "2345798.csv\n",
      "2351271.csv\n",
      "2351960.csv\n",
      "2370955.csv\n",
      "2377280.csv\n",
      "2380121.csv\n",
      "238175.csv\n",
      "2385870.csv\n",
      "238765.csv\n",
      "240002.csv\n",
      "2401011.csv\n",
      "240340.csv\n",
      "2403638.csv\n",
      "2416191.csv\n",
      "2423427.csv\n",
      "2431461.csv\n",
      "243651.csv\n",
      "2437473.csv\n",
      "2441284.csv\n",
      "2447748.csv\n",
      "2448674.csv\n",
      "2450365.csv\n",
      "2451984.csv\n",
      "2455907.csv\n",
      "2457905.csv\n",
      "245879.csv\n",
      "2461503.csv\n",
      "2464424.csv\n",
      "2474795.csv\n",
      "2475284.csv\n",
      "2484677.csv\n",
      "248708.csv\n",
      "2488161.csv\n",
      "2490118.csv\n",
      "249742.csv\n",
      "250370.csv\n",
      "2508150.csv\n",
      "2508330.csv\n",
      "2512661.csv\n",
      "251481.csv\n",
      "2516568.csv\n",
      "2519838.csv\n",
      "2520364.csv\n",
      "252147.csv\n",
      "2524294.csv\n",
      "2536629.csv\n",
      "2539541.csv\n",
      "2540996.csv\n",
      "2541302.csv\n",
      "2544255.csv\n",
      "2553132.csv\n",
      "2553865.csv\n",
      "2558336.csv\n",
      "2563311.csv\n",
      "2579410.csv\n",
      "2579694.csv\n",
      "2584300.csv\n",
      "2584673.csv\n",
      "259159.csv\n",
      "2591808.csv\n",
      "2612142.csv\n",
      "261534.csv\n",
      "2617984.csv\n",
      "262463.csv\n",
      "2625004.csv\n",
      "2642841.csv\n",
      "264312.csv\n",
      "2656520.csv\n",
      "2657736.csv\n",
      "265877.csv\n",
      "265883.csv\n",
      "2659490.csv\n",
      "2659909.csv\n",
      "2667535.csv\n",
      "2667661.csv\n",
      "2672499.csv\n",
      "267627.csv\n",
      "2682932.csv\n",
      "2694884.csv\n",
      "2697408.csv\n",
      "2704521.csv\n",
      "2706101.csv\n",
      "2706137.csv\n",
      "2708055.csv\n",
      "2722084.csv\n",
      "2727386.csv\n",
      "2738707.csv\n",
      "274424.csv\n",
      "2750379.csv\n",
      "2751944.csv\n",
      "2755844.csv\n",
      "277090.csv\n",
      "2771033.csv\n",
      "277524.csv\n",
      "277731.csv\n",
      "2780714.csv\n",
      "2785324.csv\n",
      "2790693.csv\n",
      "2800969.csv\n",
      "280945.csv\n",
      "2811295.csv\n",
      "2811507.csv\n",
      "2812504.csv\n",
      "2815597.csv\n",
      "2825270.csv\n",
      "2830223.csv\n",
      "2833181.csv\n",
      "2834129.csv\n",
      "2839253.csv\n",
      "284825.csv\n",
      "2850239.csv\n",
      "2864817.csv\n",
      "2865559.csv\n",
      "2869507.csv\n",
      "2871279.csv\n",
      "2872947.csv\n",
      "2875914.csv\n",
      "288011.csv\n",
      "2888557.csv\n",
      "2890708.csv\n",
      "2891853.csv\n",
      "289669.csv\n",
      "2898019.csv\n",
      "2900106.csv\n",
      "290117.csv\n",
      "290808.csv\n",
      "290850.csv\n",
      "2911472.csv\n",
      "2928274.csv\n",
      "2930053.csv\n",
      "294456.csv\n",
      "294934.csv\n",
      "2952161.csv\n",
      "295286.csv\n",
      "295574.csv\n",
      "2960907.csv\n",
      "297375.csv\n",
      "2974145.csv\n",
      "2980522.csv\n",
      "2985243.csv\n",
      "298563.csv\n",
      "299412.csv\n",
      "3004631.csv\n",
      "300931.csv\n",
      "3014192.csv\n",
      "3026264.csv\n",
      "3027978.csv\n",
      "3040579.csv\n",
      "3064783.csv\n",
      "306480.csv\n",
      "3075.csv\n",
      "3079914.csv\n",
      "3081864.csv\n",
      "309084.csv\n",
      "310022.csv\n",
      "3107530.csv\n",
      "3126224.csv\n",
      "3126438.csv\n",
      "312781.csv\n",
      "3130321.csv\n",
      "3136059.csv\n",
      "313835.csv\n",
      "3141790.csv\n",
      "3143897.csv\n",
      "314487.csv\n",
      "3152159.csv\n",
      "3155747.csv\n",
      "316711.csv\n",
      "3180265.csv\n",
      "3180885.csv\n",
      "3190132.csv\n",
      "319074.csv\n",
      "3197212.csv\n",
      "3204508.csv\n",
      "320685.csv\n",
      "3212385.csv\n",
      "3217228.csv\n",
      "322567.csv\n",
      "3225681.csv\n",
      "3227606.csv\n",
      "3228328.csv\n",
      "323499.csv\n",
      "3236079.csv\n",
      "3236194.csv\n",
      "325790.csv\n",
      "3263983.csv\n",
      "3266294.csv\n",
      "3280230.csv\n",
      "328330.csv\n",
      "328940.csv\n",
      "3291750.csv\n",
      "329722.csv\n",
      "330103.csv\n",
      "3301109.csv\n",
      "3302723.csv\n",
      "331463.csv\n",
      "3337272.csv\n",
      "3344033.csv\n",
      "3347663.csv\n",
      "3358257.csv\n",
      "3365880.csv\n",
      "3372135.csv\n",
      "3373682.csv\n",
      "3388232.csv\n",
      "3391490.csv\n",
      "3394339.csv\n",
      "3396268.csv\n",
      "340945.csv\n",
      "3411455.csv\n",
      "3418089.csv\n",
      "341837.csv\n",
      "3419345.csv\n",
      "343176.csv\n",
      "3445142.csv\n",
      "344562.csv\n",
      "3450382.csv\n",
      "3450589.csv\n",
      "345114.csv\n",
      "3452637.csv\n",
      "3460078.csv\n",
      "346303.csv\n",
      "3463240.csv\n",
      "347201.csv\n",
      "3478434.csv\n",
      "348348.csv\n",
      "3488554.csv\n",
      "3496560.csv\n",
      "350673.csv\n",
      "351206.csv\n",
      "3514919.csv\n",
      "3516152.csv\n",
      "3517771.csv\n",
      "351996.csv\n",
      "3521750.csv\n",
      "3529094.csv\n",
      "3533535.csv\n",
      "3535198.csv\n",
      "354196.csv\n",
      "354680.csv\n",
      "3547359.csv\n",
      "3561690.csv\n",
      "356414.csv\n",
      "3574085.csv\n",
      "3583583.csv\n",
      "3585224.csv\n",
      "3587403.csv\n",
      "3594556.csv\n",
      "3596773.csv\n",
      "3606266.csv\n",
      "3606301.csv\n",
      "361339.csv\n",
      "3614145.csv\n",
      "3620666.csv\n",
      "362109.csv\n",
      "3622246.csv\n",
      "362368.csv\n",
      "363631.csv\n",
      "364506.csv\n",
      "3648861.csv\n",
      "366362.csv\n",
      "368130.csv\n",
      "3682747.csv\n",
      "3683614.csv\n",
      "3689332.csv\n",
      "3696100.csv\n",
      "3700862.csv\n",
      "370445.csv\n",
      "371868.csv\n",
      "371878.csv\n",
      "3723757.csv\n",
      "3731062.csv\n",
      "3740.csv\n",
      "375645.csv\n",
      "3757644.csv\n",
      "376223.csv\n",
      "3770842.csv\n",
      "377171.csv\n",
      "3779497.csv\n",
      "3791501.csv\n",
      "37931.csv\n",
      "379324.csv\n",
      "3795474.csv\n",
      "3798459.csv\n",
      "3799586.csv\n",
      "3808845.csv\n",
      "381560.csv\n",
      "3816378.csv\n",
      "3818460.csv\n",
      "3832645.csv\n",
      "385713.csv\n",
      "386760.csv\n",
      "38910.csv\n",
      "391522.csv\n",
      "392501.csv\n",
      "393992.csv\n",
      "39467.csv\n",
      "395739.csv\n",
      "3986.csv\n",
      "399102.csv\n",
      "399251.csv\n",
      "399509.csv\n",
      "409969.csv\n",
      "413078.csv\n",
      "413210.csv\n",
      "415848.csv\n",
      "418568.csv\n",
      "419012.csv\n",
      "419739.csv\n",
      "420376.csv\n",
      "42203.csv\n",
      "423820.csv\n",
      "43165.csv\n",
      "437777.csv\n",
      "43823.csv\n",
      "439467.csv\n",
      "442116.csv\n",
      "442318.csv\n",
      "44309.csv\n",
      "444493.csv\n",
      "44459.csv\n",
      "446019.csv\n",
      "450629.csv\n",
      "45450.csv\n",
      "454616.csv\n",
      "455790.csv\n",
      "455818.csv\n",
      "457755.csv\n",
      "45968.csv\n",
      "459887.csv\n",
      "460378.csv\n",
      "46038.csv\n",
      "46284.csv\n",
      "467101.csv\n",
      "470115.csv\n",
      "472272.csv\n",
      "472821.csv\n",
      "4737.csv\n",
      "479958.csv\n",
      "481300.csv\n",
      "481738.csv\n",
      "483585.csv\n",
      "486934.csv\n",
      "488800.csv\n",
      "489381.csv\n",
      "492026.csv\n",
      "49370.csv\n",
      "493715.csv\n",
      "49906.csv\n",
      "50016.csv\n",
      "50230.csv\n",
      "5033.csv\n",
      "50420.csv\n",
      "50452.csv\n",
      "505799.csv\n",
      "50643509.csv\n",
      "50655124.csv\n",
      "50667561.csv\n",
      "50674114.csv\n",
      "50674376.csv\n",
      "50686116.csv\n",
      "50734876.csv\n",
      "50782750.csv\n",
      "50798971.csv\n",
      "50876284.csv\n",
      "50883370.csv\n",
      "50893532.csv\n",
      "50902387.csv\n",
      "50914512.csv\n",
      "50916271.csv\n",
      "50929631.csv\n",
      "50931287.csv\n",
      "50937756.csv\n",
      "50947405.csv\n",
      "50963136.csv\n",
      "50987143.csv\n",
      "51012206.csv\n",
      "51033485.csv\n",
      "51055506.csv\n",
      "51082587.csv\n",
      "51129468.csv\n",
      "51130819.csv\n",
      "512497.csv\n",
      "512518.csv\n",
      "51264363.csv\n",
      "51301225.csv\n",
      "51311898.csv\n",
      "51328130.csv\n",
      "51382438.csv\n",
      "51449857.csv\n",
      "515447.csv\n",
      "51560453.csv\n",
      "51940478.csv\n",
      "51997395.csv\n",
      "52006456.csv\n",
      "52007703.csv\n",
      "52011352.csv\n",
      "52040124.csv\n",
      "52077607.csv\n",
      "52077813.csv\n",
      "52114060.csv\n",
      "52170176.csv\n",
      "52191236.csv\n",
      "52266861.csv\n",
      "52267409.csv\n",
      "52269.csv\n",
      "52274.csv\n",
      "523339.csv\n",
      "52339228.csv\n",
      "523975.csv\n",
      "524048.csv\n",
      "52470803.csv\n",
      "525151.csv\n",
      "52520413.csv\n",
      "52527037.csv\n",
      "52557970.csv\n",
      "52625029.csv\n",
      "526281.csv\n",
      "52811631.csv\n",
      "52811997.csv\n",
      "52837049.csv\n",
      "528624.csv\n",
      "528652.csv\n",
      "529161.csv\n",
      "52926317.csv\n",
      "52929265.csv\n",
      "52948521.csv\n",
      "529813.csv\n",
      "53069650.csv\n",
      "53098170.csv\n",
      "53133116.csv\n",
      "53408.csv\n",
      "537467.csv\n",
      "540027.csv\n",
      "54268.csv\n",
      "544455.csv\n",
      "54878.csv\n",
      "553740.csv\n",
      "554770.csv\n",
      "55608.csv\n",
      "556374.csv\n",
      "556410.csv\n",
      "556909.csv\n",
      "558203.csv\n",
      "558968.csv\n",
      "559163.csv\n",
      "559173.csv\n",
      "562392.csv\n",
      "562642.csv\n",
      "56386.csv\n",
      "570296.csv\n",
      "571468.csv\n",
      "574577.csv\n",
      "575924.csv\n",
      "576282.csv\n",
      "577439.csv\n",
      "577798.csv\n",
      "577944.csv\n",
      "579599.csv\n",
      "57973.csv\n",
      "58067.csv\n",
      "581625.csv\n",
      "582519.csv\n",
      "585649.csv\n",
      "588756.csv\n",
      "589693.csv\n",
      "589925.csv\n",
      "59216.csv\n",
      "592841.csv\n",
      "592843.csv\n",
      "593468.csv\n",
      "595133.csv\n",
      "597665.csv\n",
      "599992.csv\n",
      "604066.csv\n",
      "604117.csv\n",
      "606115.csv\n",
      "60626.csv\n",
      "608845.csv\n",
      "60907.csv\n",
      "615031.csv\n",
      "615348.csv\n",
      "61641.csv\n",
      "618069.csv\n",
      "618129.csv\n",
      "621065.csv\n",
      "622305.csv\n",
      "623861.csv\n",
      "625857.csv\n",
      "630138.csv\n",
      "630312.csv\n",
      "632683.csv\n",
      "63283.csv\n",
      "63517.csv\n",
      "63747.csv\n",
      "64598.csv\n",
      "647545.csv\n",
      "647820.csv\n",
      "648294.csv\n",
      "652114.csv\n",
      "652155.csv\n",
      "655613.csv\n",
      "66585.csv\n",
      "670076.csv\n",
      "670305.csv\n",
      "671637.csv\n",
      "671985.csv\n",
      "67379.csv\n",
      "67892.csv\n",
      "679806.csv\n",
      "68308.csv\n",
      "690900.csv\n",
      "695088.csv\n",
      "695584.csv\n",
      "696261.csv\n",
      "696825.csv\n",
      "699151.csv\n",
      "70020.csv\n",
      "701860.csv\n",
      "702942.csv\n",
      "70315.csv\n",
      "703488.csv\n",
      "706650.csv\n",
      "707930.csv\n",
      "708521.csv\n",
      "709620.csv\n",
      "70986.csv\n",
      "711489.csv\n",
      "712322.csv\n",
      "715167.csv\n",
      "716617.csv\n",
      "719979.csv\n",
      "720273.csv\n",
      "720783.csv\n",
      "722501.csv\n",
      "726151.csv\n",
      "728429.csv\n",
      "734633.csv\n",
      "735176.csv\n",
      "736528.csv\n",
      "739770.csv\n",
      "741791.csv\n",
      "742176.csv\n",
      "746774.csv\n",
      "747500.csv\n",
      "75200.csv\n",
      "752694.csv\n",
      "754282.csv\n",
      "756836.csv\n",
      "757387.csv\n",
      "7585.csv\n",
      "759988.csv\n",
      "760333.csv\n",
      "761492.csv\n",
      "762314.csv\n",
      "76252.csv\n",
      "763791.csv\n",
      "766300.csv\n",
      "7672.csv\n",
      "767288.csv\n",
      "770812.csv\n",
      "772715.csv\n",
      "777352.csv\n",
      "777623.csv\n",
      "78231.csv\n",
      "782651.csv\n",
      "787927.csv\n",
      "787997.csv\n",
      "788959.csv\n",
      "790333.csv\n",
      "793333.csv\n",
      "795427.csv\n",
      "797572.csv\n",
      "806373.csv\n",
      "80696.csv\n",
      "8095.csv\n",
      "817466.csv\n",
      "820730.csv\n",
      "82413.csv\n",
      "825643.csv\n",
      "827409.csv\n",
      "827624.csv\n",
      "8300.csv\n",
      "833109.csv\n",
      "833172.csv\n",
      "8351.csv\n",
      "837456.csv\n",
      "838629.csv\n",
      "83895.csv\n",
      "840622.csv\n",
      "845266.csv\n",
      "84783.csv\n",
      "850294.csv\n",
      "851595.csv\n",
      "852908.csv\n",
      "855002.csv\n",
      "858538.csv\n",
      "859482.csv\n",
      "861478.csv\n",
      "864356.csv\n",
      "866345.csv\n",
      "868762.csv\n",
      "86939.csv\n",
      "870413.csv\n",
      "8716.csv\n",
      "871709.csv\n",
      "874840.csv\n",
      "874862.csv\n",
      "87603.csv\n",
      "876268.csv\n",
      "877017.csv\n",
      "878467.csv\n",
      "879937.csv\n",
      "88371.csv\n",
      "884153.csv\n",
      "886285.csv\n",
      "891378.csv\n",
      "891723.csv\n",
      "893552.csv\n",
      "89644.csv\n",
      "897299.csv\n",
      "898417.csv\n",
      "9039.csv\n",
      "90447.csv\n",
      "904930.csv\n",
      "905775.csv\n",
      "90698.csv\n",
      "907187.csv\n",
      "909222.csv\n",
      "910077.csv\n",
      "916486.csv\n",
      "918090.csv\n",
      "922045.csv\n",
      "92450.csv\n",
      "926691.csv\n",
      "933559.csv\n",
      "936912.csv\n",
      "939726.csv\n",
      "948305.csv\n",
      "950070.csv\n",
      "952194.csv\n",
      "965420.csv\n",
      "966302.csv\n",
      "9700.csv\n",
      "97205.csv\n",
      "973172.csv\n",
      "975107.csv\n",
      "980182.csv\n",
      "981787.csv\n",
      "98217.csv\n",
      "984106.csv\n",
      "984155.csv\n",
      "984900.csv\n",
      "984982.csv\n",
      "98513.csv\n",
      "991714.csv\n",
      "994118.csv\n",
      "997083.csv\n"
     ]
    }
   ],
   "source": [
    "pattern = set_pattern_time()\n",
    "count = 0\n",
    "for file_name in df_files.itertuples():\n",
    "    count +=1\n",
    "    # start = time.time()\n",
    "    print(file_name.file_name)\n",
    "    # Read file with segmented sentences\n",
    "    biography_df = pd.read_csv('indexedSentences/'+file_name.file_name)\n",
    "    df_time_ent = pd.DataFrame()\n",
    "    # df_entities = pd.DataFrame()\n",
    "    \n",
    "    # for each sentence in each biography\n",
    "    for sentence_row in biography_df.itertuples():\n",
    "        # now use the same sentence to analyse if a time entity is present\n",
    "        # for sentence_row in biography_df.itertuples():\n",
    "        df_temp = pd.DataFrame()\n",
    "        timeEntityList = []\n",
    "        #added to include timeEntityType\n",
    "        timeEntityTypeList = []\n",
    "\n",
    "        tokenized_sent=nt.word_tokenize(sentence_row.sentences)\n",
    "        pos_sentences=nltk.pos_tag(tokenized_sent)\n",
    "        cp = nltk.RegexpParser(pattern)\n",
    "        cs = cp.parse(pos_sentences)\n",
    "\n",
    "        # loop to search for the POST TAGs related to TIME\n",
    "        for ne in cs:\n",
    "            res = \"\"\n",
    "            if hasattr(ne, \"label\"):\n",
    "                # print(type(ne[0:]))\n",
    "                # print(ne.label(), ne[0:])\n",
    "\n",
    "                for i in ne[0:]:\n",
    "                    res += i[0] + \" \"\n",
    "                res = res.strip()\n",
    "                # print(res)\n",
    "                    # print(t)\n",
    "                \n",
    "                # added to include timeEntityType\n",
    "                time_type = \"\"\n",
    "                if ne.label() == \"RN\":\n",
    "                    # then type is RANGE\n",
    "                    time_type = \"TimeRange\"\n",
    "                else:\n",
    "                    time_type = \"TimePoint\"\n",
    "                if ('–' in res):\n",
    "                    time_type = \"TimeRange\"\n",
    "                timeEntityTypeList.append(time_type)\n",
    "                \n",
    "                #added to include timeEntityType\n",
    "                timeEntityList.append(res)\n",
    "                \n",
    "        # if we have some time entities indentified\n",
    "        if timeEntityList:\n",
    "            df_temp['entity']=timeEntityList\n",
    "            df_temp['sentence']= sentence_row.sentences\n",
    "            df_temp['sentenceIndex']=sentence_row.sentenceIndex\n",
    "            df_temp['paragraphIndex'] = sentence_row.paragraphIndex\n",
    "            df_temp['section'] = sentence_row.section\n",
    "            df_temp['entType'] = 'time'\n",
    "            df_temp['wikiPageID'] = sentence_row.wikiId\n",
    "            #added to include timeEntityType\n",
    "            df_temp['timeEntityType']=timeEntityTypeList\n",
    "\n",
    "            df_time_ent = df_time_ent.append(df_temp)\n",
    "\n",
    "    # # append time\n",
    "    df_entities = pd.read_csv('extractedEntitiesPersonPlaceOnly/'+file_name.file_name)\n",
    "    df_entities.append(df_time_ent).to_csv('extractedEntities/'+file_name.file_name,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fd46b25-d969-49f5-90ca-c4525b856f35",
   "metadata": {},
   "outputs": [],
   "source": [
    "### TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "ec104225-0c8e-41bc-8c5a-fdd296c5eb13",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "+ = match 1 or more\n",
    "? = match 0 or 1 repetitions.\n",
    "* = match 0 or MORE repetitions\t  \n",
    ". = Any character except a new line\n",
    "CD\tcardinal digit\n",
    "DT\tdeterminer\n",
    "NN\tnoun, singular 'desk'\n",
    "NNS\tnoun plural\t'desks'\n",
    "NNP\tproper noun, singular\t'Harrison'\n",
    "NNPS\tproper noun, plural\t'Americans'\n",
    "IN\tpreposition/subordinating conjunction\n",
    "RB\tadverb\tvery, silently,\n",
    "RBR\tadverb, comparative\tbetter\n",
    "RBS\tadverb, superlative\tbest\n",
    "\"\"\"\n",
    "def set_pattern_time():\n",
    "    pattern = r\"\"\"DT1: #dates, time point\n",
    "    {<CD?><NNP|CD?><CD?>} #complete dates Eg. 23 January 1983\n",
    "    {<NNP?><CD?><,?><CD?>} # December 13, 2000\n",
    "    {<CD?></><CD?></><CD?>} #complete dates 23/02/2021\n",
    "    {<CD?><-><CD?><-><CD?>} #complete dates 23-02-2021\n",
    "    HO: # HOURS\n",
    "    {<CD>+<NN>+} # hour only\n",
    "    RN: # range \n",
    "    {<IN><CD>+<IN|TO|CC>+<CD>+} # between YYYY and <> YYYY, from 1938 to 1939\n",
    "    DT2: #date from explicit, to implicit DT2 [('each', 'DT'), ('one', 'CD')]\n",
    "    {<IN>+<DT>?<\\d>} # \"in XXXX\" (year)\n",
    "    <\\W?>{<CD>}<\\W?> # year in between special characters\n",
    "    {<NNP><CD>} #incomplete date January 2003, Fall 1994\n",
    "    {<IN>+<DT>+<CD>+} # years dt the 1990s, leukemia in 1996, age of 43,the 1990s\n",
    "    {<NN>+<IN|DT>+<CD>} # years dt the 1990s, leukemia in 1996, age of 43,the 1990s\n",
    "    {<CD><IN>} # 1984 novel,1954–58\n",
    "    DT3:\n",
    "    <DT>+{<CD>}\n",
    "    REF: # references, implicit\n",
    "    {<IN>+<NN>+<CD>+} # by age 43\n",
    "    {<NN><IN><CD>} # Eg. fall/winter of 1345, age of 43\n",
    "    <NN>{<DT>+<CD>} # Eg. fall/winter of 1345, age of 43\n",
    "    \"\"\"\n",
    "    return pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "8d7bc8e2-8198-4c8a-82b4-b135d4c79df4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  He/PRP\n",
      "  is/VBZ\n",
      "  (DT2 one/CD of/IN)\n",
      "  the/DT\n",
      "  leaders/NNS\n",
      "  of/IN\n",
      "  musical/JJ\n",
      "  art/NN\n",
      "  of/IN\n",
      "  modern/JJ\n",
      "  times/NNS\n",
      "  ./.\n",
      "  She/PRP\n",
      "  had/VBD\n",
      "  a/DT\n",
      "  related/JJ\n",
      "  UK/NNP\n",
      "  single/JJ\n",
      "  release/NN\n",
      "  as/IN\n",
      "  'Jennifer/NN\n",
      "  '/''\n",
      "  on/IN\n",
      "  London/NNP\n",
      "  (DT2 HLU/NNP 10278/CD)\n",
      "  in/IN\n",
      "  (DT2 June/NNP 1969/CD)\n",
      "  with/IN\n",
      "  'Let/PDT\n",
      "  The/DT\n",
      "  Sunshine/NNP\n",
      "  In/IN\n",
      "  '/POS\n",
      "  and/CC\n",
      "  'Easy/CD\n",
      "  to/TO\n",
      "  Be/VB\n",
      "  Hard/NNP\n",
      "  '/POS\n",
      "  ,/,\n",
      "  licensed/VBN\n",
      "  from/IN\n",
      "  the/DT\n",
      "  US/NNP\n",
      "  Parrot/NNP\n",
      "  label/NN\n",
      "  ./.\n",
      "  However/RB\n",
      "  ,/,\n",
      "  (DT2 in/IN the/DT 1957/CD)\n",
      "  centenary/JJ\n",
      "  symposium/NN\n",
      "  ,/,\n",
      "  several/JJ\n",
      "  leading/VBG\n",
      "  admirers/NNS\n",
      "  of/IN\n",
      "  Elgar/NNP\n",
      "  express/NN\n",
      "  reservations/NNS\n",
      "  about/IN\n",
      "  one/CD\n",
      "  or/CC\n",
      "  both/DT\n",
      "  symphonies/NNS\n",
      "  ./.\n",
      "  By/IN\n",
      "  the/DT\n",
      "  (DT2 age/NN of/IN eight/CD)\n",
      "  ,/,\n",
      "  Elgar/NNP\n",
      "  was/VBD\n",
      "  taking/VBG\n",
      "  piano/NN\n",
      "  and/CC\n",
      "  the/DT\n",
      "  (DT3 1990s/CD)\n",
      "  ,/,\n",
      "  (DT2 leukemia/NN in/IN 1996/CD)\n",
      "  ,/,\n",
      "  (DT2 age/NN of/IN 43/CD)\n",
      "  ,/,\n",
      "  the/DT\n",
      "  (HO 1990s/CD violin/NN)\n",
      "  lessons/NNS\n",
      "  ,/,\n",
      "  and/CC\n",
      "  his/PRP$\n",
      "  father/NN\n",
      "  ,/,\n",
      "  who/WP\n",
      "  tuned/VBD\n",
      "  the/DT\n",
      "  pianos/NN\n",
      "  at/IN\n",
      "  many/JJ\n",
      "  grand/JJ\n",
      "  houses/NNS\n",
      "  in/IN\n",
      "  Worcestershire/NNP\n",
      "  ,/,\n",
      "  would/MD\n",
      "  sometimes/RB\n",
      "  take/VB\n",
      "  him/PRP\n",
      "  along/RB\n",
      "  ,/,\n",
      "  giving/VBG\n",
      "  him/PRP\n",
      "  the/DT\n",
      "  chance/NN\n",
      "  to/TO\n",
      "  display/VB\n",
      "  his/PRP$\n",
      "  skill/NN\n",
      "  to/TO\n",
      "  important/JJ\n",
      "  local/JJ\n",
      "  figures/NNS\n",
      "  ./.\n",
      "  The/DT\n",
      "  Variations/NNS\n",
      "  have/VBP\n",
      "  amused/VBN\n",
      "  me/PRP\n",
      "  because/IN\n",
      "  I/PRP\n",
      "  've/VBP\n",
      "  labelled/VBN\n",
      "  them/PRP\n",
      "  with/IN\n",
      "  the/DT\n",
      "  nicknames/NNS\n",
      "  of/IN\n",
      "  my/PRP$\n",
      "  particular/JJ\n",
      "  friends/NNS\n",
      "  .../:\n",
      "  that/WDT\n",
      "  is/VBZ\n",
      "  to/TO\n",
      "  say/VB\n",
      "  I/PRP\n",
      "  've/VBP\n",
      "  written/VBN\n",
      "  the/DT\n",
      "  variations/NNS\n",
      "  each/DT\n",
      "  (DT3 one/CD)\n",
      "  to/TO\n",
      "  represent/VB\n",
      "  the/DT\n",
      "  mood/NN\n",
      "  of/IN\n",
      "  the/DT\n",
      "  'party/NN\n",
      "  '/POS\n",
      "  (/(\n",
      "  the/DT\n",
      "  person/NN\n",
      "  )/)\n",
      "  .../:\n",
      "  and/CC\n",
      "  have/VBP\n",
      "  written/VBN\n",
      "  what/WP\n",
      "  I/PRP\n",
      "  think/VBP\n",
      "  they/PRP\n",
      "  would/MD\n",
      "  have/VB\n",
      "  written/VBN\n",
      "  –/RP\n",
      "  if/IN\n",
      "  they/PRP\n",
      "  were/VBD\n",
      "  asses/NNS\n",
      "  enough/RB\n",
      "  to/TO\n",
      "  compose/VB\n",
      "  '/POS\n",
      "  ./.)\n",
      "DT2 [('one', 'CD'), ('of', 'IN')]\n",
      "one of\n",
      "TimePoint\n",
      "DT2 [('HLU', 'NNP'), ('10278', 'CD')]\n",
      "HLU 10278\n",
      "TimePoint\n",
      "DT2 [('June', 'NNP'), ('1969', 'CD')]\n",
      "June 1969\n",
      "TimePoint\n",
      "DT2 [('in', 'IN'), ('the', 'DT'), ('1957', 'CD')]\n",
      "in the 1957\n",
      "TimePoint\n",
      "DT2 [('age', 'NN'), ('of', 'IN'), ('eight', 'CD')]\n",
      "age of eight\n",
      "TimePoint\n",
      "DT3 [('1990s', 'CD')]\n",
      "1990s\n",
      "TimePoint\n",
      "DT2 [('leukemia', 'NN'), ('in', 'IN'), ('1996', 'CD')]\n",
      "leukemia in 1996\n",
      "TimePoint\n",
      "DT2 [('age', 'NN'), ('of', 'IN'), ('43', 'CD')]\n",
      "age of 43\n",
      "TimePoint\n",
      "HO [('1990s', 'CD'), ('violin', 'NN')]\n",
      "1990s violin\n",
      "TimePoint\n",
      "DT3 [('one', 'CD')]\n",
      "one\n",
      "TimePoint\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n    Classification:\\n    Time FROM and TO: \\n        RN\\n    Time point:\\n        DT1, DT2,HO, REF\\n'"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timeEntityList = []\n",
    "timeEntityTypeList = []\n",
    "sentence =\"He is one of the leaders of musical art of modern times. She had a related UK single release as 'Jennifer' on London HLU 10278 in June 1969 with 'Let The Sunshine In' and 'Easy to Be Hard', licensed from the US Parrot label.\tHowever, in the 1957 centenary symposium, several leading admirers of Elgar express reservations about one or both symphonies. By the age of eight, Elgar was taking piano and the 1990s, leukemia in 1996, age of 43, the 1990s violin lessons, and his father, who tuned the pianos at many grand houses in Worcestershire, would sometimes take him along, giving him the chance to display his skill to important local figures. The Variations have amused me because I've labelled them with the nicknames of my particular friends ... that is to say I've written the variations each one to represent the mood of the 'party' (the person) ... and have written what I think they would have written – if they were asses enough to compose'.\"\n",
    "pattern = set_pattern_time()\n",
    "tokenized_sent=nt.word_tokenize(sentence)\n",
    "pos_sentences=nltk.pos_tag(tokenized_sent)\n",
    "cp = nltk.RegexpParser(pattern)\n",
    "cs = cp.parse(pos_sentences)\n",
    "print(cs)\n",
    "\n",
    "# loop to search for the POST TAGs related to TIME\n",
    "for ne in cs:\n",
    "    res = \"\"\n",
    "    if hasattr(ne, \"label\"):\n",
    "        # print(type(ne[0:]))\n",
    "        # ne is a list\n",
    "        print(ne.label(), ne[0:])\n",
    "        time_type = \"\"\n",
    "        if ne.label() == \"RN\":\n",
    "            # then type is RANGE\n",
    "            time_type = \"TimeRange\"\n",
    "        else:\n",
    "            time_type = \"TimePoint\"\n",
    "        \n",
    "        for i in ne[0:]:\n",
    "            res += i[0] + \" \"\n",
    "        res = res.strip()\n",
    "        print(res)\n",
    "        if ('–' in res):\n",
    "            time_type = \"TimeRange\"\n",
    "            # print(time_type)\n",
    "        \n",
    "        # print(t)\n",
    "        print(time_type)\n",
    "        timeEntityList.append(res)\n",
    "        timeEntityTypeList.append(res)\n",
    "        \n",
    "\"\"\"\n",
    "    Classification:\n",
    "    Time FROM and TO: \n",
    "        RN\n",
    "    Time point:\n",
    "        DT1, DT2,HO, REF\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69d0698f-19fb-416e-a03c-785a1feb6f74",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8662400a-c28f-46ba-95c5-49ef5a9e5dbc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
